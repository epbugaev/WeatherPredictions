{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "562de70c-a78b-453a-b8ef-5036dd36a586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn, einsum\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import rearrange\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from fairscale.nn.checkpoint.checkpoint_activations import checkpoint_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad1a81b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fa.buzaev/.conda/envs/my_py_env1/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload\n",
    "\n",
    "from Models.WeatherGFT import GFT\n",
    "from utils.dataloader import load_data\n",
    "from utils.losses import weighted_rmse, weighted_mae, calculate_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a702e025-d4c9-420d-b486-3696a59f15b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5740d9-82b6-4768-9a78-13b9637405f0",
   "metadata": {},
   "source": [
    "## dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4b95640-f05c-4702-ae37-39ae3c25e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/home/fratnikov/weather_bench/'\n",
    "prediction_horizone = 72\n",
    "\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413a9415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def copy_weather_data():\n",
    "    # Исходная и целевая директории\n",
    "    source_root = '/home/fratnikov/weather_bench/1.40625deg'\n",
    "    target_root = '/home/fa.buzaev/data_to_debug'\n",
    "    \n",
    "    # Годы для копирования\n",
    "    target_years = ['2015', '2018']\n",
    "    \n",
    "    # Создаем корневую целевую директорию\n",
    "    Path(target_root).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Проходим по всем поддиректориям в исходной директории\n",
    "    for variable_dir in os.listdir(source_root):\n",
    "        source_dir = os.path.join(source_root, variable_dir)\n",
    "        \n",
    "        # Пропускаем, если это не директория\n",
    "        if not os.path.isdir(source_dir):\n",
    "            continue\n",
    "            \n",
    "        # Создаем соответствующую директорию в целевой папке\n",
    "        target_dir = os.path.join(target_root, variable_dir)\n",
    "        Path(target_dir).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Копируем файлы только нужных годов\n",
    "        for file in os.listdir(source_dir):\n",
    "            if any(f'_{year}_1.40625deg.nc' in file for year in target_years):\n",
    "                source_file = os.path.join(source_dir, file)\n",
    "                target_file = os.path.join(target_dir, file)\n",
    "                print(source_file)\n",
    "                print(target_file)\n",
    "                # shutil.copy2(source_file, target_file)\n",
    "                print(f'Скопирован файл: {file}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        copy_weather_data()\n",
    "        print('Копирование завершено успешно')\n",
    "    except Exception as e:\n",
    "        print(f'Произошла ошибка при копировании: {str(e)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a1ce62-61da-45a1-9bd5-a1df70bb6051",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train, dataloader_vali, dataloader_test, mean, std = load_data(batch_size=batch_size,\n",
    "                                                                          val_batch_size=batch_size,\n",
    "                                                                          data_root=data_root,\n",
    "                                                                          num_workers=10,\n",
    "                                                                          data_split='1_40625', # Разрешение и размерная сетка\n",
    "                                                                          # data_split='5_625',\n",
    "                                                                          data_name='mv_gft', # Название данных\n",
    "                                                                          train_time=['2018', '2018'],\n",
    "                                                                          # train_time=['2015', '2015'],\n",
    "                                                                          # val_time=['2016', '2016'],\n",
    "                                                                          # test_time=['2018', '2018'],\n",
    "                                                                          val_time=None,\n",
    "                                                                          test_time=None,\n",
    "                                                                          idx_in=[0], # Размерность по T\n",
    "                                                                          idx_out=[*range(1, prediction_horizone+1)],\n",
    "                                                                          step=1,\n",
    "                                                                          levels='all', \n",
    "                                                                          distributed=False, use_augment=False,\n",
    "                                                                          use_prefetcher=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "567769b5-f35b-40ab-bff4-0511bdbacc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_iterator = iter(dataloader_train)\n",
    "\n",
    "x_test, y_test = next(test_iterator)\n",
    "x_test, y_test = x_test.to(device), y_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfafe528-af21-41f6-a2a2-a0ddffd206bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.Tensor(mean).unsqueeze(0)  # [1, 1, 69, 1, 1]\n",
    "std = torch.Tensor(std).unsqueeze(0)    # [1, 1, 69, 1, 1]\n",
    "\n",
    "mean = mean.to(device)\n",
    "std = std.to(device)\n",
    "\n",
    "# Денормализация\n",
    "x_test = x_test * std + mean\n",
    "y_test = y_test * std + mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475431e7",
   "metadata": {},
   "source": [
    "Эта фигня нужна была только для того, чтобы взять std и mean, с которыми модель обучалась"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edc1783-b635-4ab0-b7da-9ab073c69e1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('example_data/mean_std.json') as f:\n",
    "    d = json.load(f)\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57af95e8-e25e-4658-8d3b-e4097694ee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(x_test.shape[2]):\n",
    "    x_test[:, :, idx] = (x_test[:, :, idx] - d['mean'][idx]) / d['std'][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02d6e6c8-f5de-49c4-8427-2d50c26a5713",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(x_test.shape[2]):\n",
    "    y_test[:, :, idx] = (y_test[:, :, idx] - d['mean'][idx]) / d['std'][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6c5fe63-5c1f-42fd-b282-86599b3de6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GFT(hidden_dim=256,\n",
    "            encoder_layers=[2, 2, 2],\n",
    "            edcoder_heads=[3, 6, 6],\n",
    "            encoder_scaling_factors=[0.5, 0.5, 1], # [128, 256] --> [64, 128] --> [32, 64] --> [32, 64], that is, patch size = 4 (128/32)\n",
    "            encoder_dim_factors=[-1, 2, 2],\n",
    "\n",
    "            body_layers=[4, 4, 4, 4, 4, 4], # A total of 4x6=24 HybridBlock, corresponding to 6 hours (24x15min) of time evolution\n",
    "            body_heads=[8, 8, 8, 8, 8, 8],\n",
    "            body_scaling_factors=[1, 1, 1, 1, 1, 1],\n",
    "            body_dim_factors=[1, 1, 1, 1, 1, 1],\n",
    "\n",
    "            decoder_layers=[2, 2, 2],\n",
    "            decoder_heads=[6, 6, 3],\n",
    "            decoder_scaling_factors=[1, 2, 1],\n",
    "            decoder_dim_factors=[1, 0.5, 1],\n",
    "\n",
    "            channels=69,\n",
    "            head_dim=128,\n",
    "            window_size=[4,8],\n",
    "            relative_pos_embedding=False,\n",
    "            out_kernel=[2,2],\n",
    "\n",
    "            pde_block_depth=3, # 1 HybridBlock contains 3 PDE kernels, corresponding to 15 minutes (3x300s) of time evolution\n",
    "            block_dt=300, # One PDE kernel corresponds to 300s of time evolution\n",
    "            inverse_time=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2bb52b-f3a8-48a8-8ea6-3aa4d2768e57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('checkpoints/gft.ckpt'):\n",
    "    ckpt = torch.load('checkpoints/gft.ckpt', map_location=device)\n",
    "    model.load_state_dict(ckpt, strict=True)\n",
    "    print('[complete loading model]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a6aa95-dc49-4f93-874e-510cfee94d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считаем количество параметров\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(f'Количество параметров в модели: {total_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db2f8b9c-1590-42aa-953d-2601ff496410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Извлекаем веса всех слоев\n",
    "weights = []\n",
    "for param in model.parameters():\n",
    "    if param.requires_grad:  # Это означает, что параметр обновляется во время обучения\n",
    "        weights.append(param.data.cpu().numpy())  # Переводим в numpy для удобства\n",
    "\n",
    "# Объединяем все веса в один массив для построения гистограммы\n",
    "all_weights = np.concatenate([w.flatten() for w in weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894f224c-7561-46d5-a005-b17b53ae301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Строим гистограмму\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(all_weights, bins=1000, color='blue', alpha=0.7)\n",
    "plt.title('Distribution of Weights in the Model')\n",
    "plt.xlabel('Weight Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.xlim(-0.2, 0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1573a291-76df-4660-892d-854e9ba88f59",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# outputs_full = torch.empty(x_test.shape, device=device)\n",
    "outputs_full = np.empty([8, 72, 3, 69, 128, 256])\n",
    "x_test_ = x_test[:, 0]\n",
    "for j in range(72):\n",
    "    with torch.no_grad():\n",
    "        res = model(x_test_)\n",
    "    outputs_full[:, j] = res.cpu().detach().numpy()\n",
    "    x_test_ = res[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc50282-2d9d-4180-b10d-0c50ce272b0c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs_every_3 = np.empty([8, 72, 3, 69, 128, 256])  # размерность подгоните под задачу\n",
    "x_test_ = x_test[:, 0]\n",
    "\n",
    "for j in range(72):\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        res = model(x_test_)\n",
    "        if j == 0:\n",
    "            res_3 = res[:, 1]\n",
    "            \n",
    "        # Если j+1 кратно 3, обновляем x_test_ предсказанием с нулевого шага\n",
    "        if (j + 1) % 3 == 0:\n",
    "            x_test_ = res_3\n",
    "            res_3 = res[:, 1]\n",
    "        else:\n",
    "            # Иначе продолжаем предсказывать на основе последнего результата\n",
    "            x_test_ = res[:, 0]\n",
    "        \n",
    "    # Сохраняем предсказание для текущего шага\n",
    "    outputs_every_3[:, j] = res.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d612f03f-fafd-4f3c-abe4-f09bd895beb0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs_every_6 = np.empty([8, 72, 3, 69, 128, 256])  # размерность подгоните под задачу\n",
    "x_test_ = x_test[:, 0]\n",
    "\n",
    "for j in range(72):\n",
    "    with torch.no_grad():\n",
    "        res = model(x_test_)\n",
    "        \n",
    "        if j == 0:\n",
    "            res_3 = res[:, 1]\n",
    "            res_6 = res[:, 2]  # сохраняем предсказание для шестого часа\n",
    "    \n",
    "    # Сохраняем предсказание для текущего шага\n",
    "    outputs_every_6[:, j] = res.cpu().detach().numpy()\n",
    "    \n",
    "    # Обновляем x_test_ в зависимости от текущего часа\n",
    "    if (j + 1) % 6 == 0:        # Каждые 6 часов\n",
    "        x_test_ = res_6\n",
    "        res_6 = res[:, 2]\n",
    "    elif (j + 1) % 3 == 0:       # Каждые 3 часа (если не кратно 6)\n",
    "        x_test_ = res_3\n",
    "        res_3 = res[:, 1]\n",
    "    else:                        # Остальные часы\n",
    "        x_test_ = res[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae11051-7efa-4db6-a3b9-f7b98771fc81",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs_every_6_2 = np.empty([8, 72, 3, 69, 128, 256], dtype=np.half)  # размерность подгоните под задачу\n",
    "x_test_ = x_test[:, 0]\n",
    "\n",
    "for j in range(72):\n",
    "    with torch.no_grad():\n",
    "        res = model(x_test_)\n",
    "        \n",
    "        if j == 0:\n",
    "            res_6 = res[:, 2]  # сохраняем предсказание для шестого часа\n",
    "    \n",
    "    # Сохраняем предсказание для текущего шага\n",
    "    outputs_every_6_2[:, j] = res.cpu().detach().numpy()\n",
    "    \n",
    "    # Обновляем x_test_ в зависимости от текущего часа\n",
    "    if (j + 1) % 6 == 0:        # Каждые 6 часов\n",
    "        x_test_ = res_6\n",
    "        res_6 = res[:, 2]\n",
    "    else:                        # Остальные часы\n",
    "        x_test_ = res[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8d07cdb-cf67-44eb-8b4d-57534c4c3482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(item, std, mean, idx=0):\n",
    "    mean = mean[idx]\n",
    "    std = std[idx]\n",
    "    item_denorm = item * std + mean\n",
    "    return item_denorm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_py_env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
